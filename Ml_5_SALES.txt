# -------------------------------
# ðŸ“˜ Assignment B-6: K-Means Clustering on Sales Data
# -------------------------------

# Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Step 2: Load dataset
df = pd.read_csv("C:/Users/Aishwarya/Downloads/sales_data_sample (1).csv", encoding='latin1')

# Display first few rows
print("âœ… Dataset Loaded Successfully")
print(df.head())

# Step 3: Select numerical columns for clustering
# (You can choose any continuous features; here weâ€™ll use 'SALES' and 'QUANTITYORDERED')
data = df[['SALES', 'QUANTITYORDERED']]

# Step 4: Handle missing values (if any)
data = data.dropna()

# Step 5: Normalize (scale) the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# Step 6: Use Elbow Method to find optimal K
wcss = []  # within-cluster sum of squares

for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

# Step 7: Plot Elbow graph
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('WCSS (Within Cluster Sum of Squares)')
plt.show()

# Step 8: Apply K-Means with the best K (letâ€™s assume K=3 based on elbow)
kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)
y_kmeans = kmeans.fit_predict(scaled_data)

# Step 9: Add cluster labels to data
data['Cluster'] = y_kmeans

# Step 10: Visualize clusters
plt.figure(figsize=(8,6))
plt.scatter(data['SALES'], data['QUANTITYORDERED'], c=data['Cluster'], cmap='viridis')
plt.title('K-Means Clustering of Sales Data')
plt.xlabel('Sales')
plt.ylabel('Quantity Ordered')
plt.show()

# Step 11: Print cluster centers
print("\nCluster Centers:")
print(kmeans.cluster_centers_)
